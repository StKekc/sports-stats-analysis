#!/usr/bin/env python3
"""
–ó–∞–¥–∞—á–∞ 5: –ü—Ä–æ–≥–Ω–æ–∑ –∏—Å—Ö–æ–¥–∞ –º–∞—Ç—á–∞ (ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏:
1. Feature Engineering (–æ–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, —Ç–∞–±–ª–∏—Ü—ã, –ª–∏—á–Ω—ã–µ –≤—Å—Ç—Ä–µ—á–∏)
2. ML Pipeline (VectorAssembler, RandomForest)
3. Time-based train/test split
4. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ (accuracy, f1-score)
5. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–ê–≤—Ç–æ—Ä: Sports Stats Analysis Project
–î–∞—Ç–∞: 2025
"""

import sys
import os
import logging
from pathlib import Path
from datetime import datetime
import yaml
import argparse
import pandas as pd

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Java –î–û –∏–º–ø–æ—Ä—Ç–∞ PySpark
if sys.platform == 'win32':
    project_root = Path(__file__).parent
    sys.path.insert(0, str(project_root))
    try:
        from modules.data_processing.java_setup import setup_java_for_spark

        setup_java_for_spark()
    except ImportError:
        if 'JAVA_HOME' not in os.environ:
            java_home = "C:\\Program Files\\Java\\jdk-17"
            if os.path.exists(java_home):
                os.environ['JAVA_HOME'] = java_home
                print(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω JAVA_HOME: {java_home}")

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º –ø—Ä–æ–µ–∫—Ç–∞
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from modules.data_processing.spark_processor import SparkProcessor
from modules.visualization.task_5_vizualizer import MatchPredictionVisualizer


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
def setup_logging(log_level: str = "INFO", log_dir: str = "logs"):
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    import sys

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤
    log_path = Path(log_dir)
    log_path.mkdir(parents=True, exist_ok=True)

    log_file = log_path / f'task5_analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'

    # StreamHandler —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –¥–ª—è Windows
    stream_handler = logging.StreamHandler()
    if sys.platform == 'win32':
        original_emit = stream_handler.emit

        def safe_emit(record):
            try:
                original_emit(record)
            except UnicodeEncodeError:
                record.msg = str(record.msg).encode('ascii', errors='replace').decode('ascii')
                original_emit(record)

        stream_handler.emit = safe_emit

    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            stream_handler,
            logging.FileHandler(str(log_file), encoding='utf-8')
        ]
    )


def load_config(config_path: str = None) -> dict:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ YAML —Ñ–∞–π–ª–∞
    """
    logger = logging.getLogger(__name__)

    if config_path is None:
        script_dir = Path(__file__).parent
        config_file = script_dir.parent / "database" / "config.yaml"
    else:
        config_file = Path(config_path)
        if not config_file.exists() and not config_file.is_absolute():
            script_dir = Path(__file__).parent
            config_file = script_dir.parent / config_path

    if not config_file.exists():
        raise FileNotFoundError(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_file.absolute()}")

    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    logger.info(f" –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {config_file.absolute()}")
    return config


def run_task5_analysis(
        db_config: dict,
        league_filter: str = 'epl',
        train_seasons_end: str = None,
        test_season: str = None,
        test_seasons_count: int = 1,
        features: list = None,
        output_dir: str = "outputs/task5",
        skip_visualizations: bool = False
):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å—Ö–æ–¥–æ–≤ –º–∞—Ç—á–µ–π (–ó–∞–¥–∞—á–∞ 5)

    Args:
        db_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
        league_filter: –§–∏–ª—å—Ç—Ä –ø–æ –ª–∏–≥–µ
        train_seasons_end: –ü–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–∑–æ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (None = –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ)
        test_season: –°–µ–∑–æ–Ω –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (None = –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ test_seasons_count —Å–µ–∑–æ–Ω–æ–≤)
        test_seasons_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–µ–∑–æ–Ω–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ test_season=None)
        features: –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        skip_visualizations: –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    """
    logger = logging.getLogger(__name__)

    logger.info("=" * 80)
    logger.info(" –ó–ê–î–ê–ß–ê 5: –ü–†–û–ì–ù–û–ó –ò–°–•–û–î–ê –ú–ê–¢–ß–ê (ML –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø)")
    logger.info("=" * 80)
    logger.info("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞:")
    logger.info(f"  - –õ–∏–≥–∞: {league_filter}")
    if train_seasons_end:
        logger.info(f"  - –û–±—É—á–∞—é—â–∏–µ —Å–µ–∑–æ–Ω—ã: –¥–æ {train_seasons_end} –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ")
    else:
        logger.info(f"  - –û–±—É—á–∞—é—â–∏–µ —Å–µ–∑–æ–Ω—ã: –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)")
    if test_season:
        logger.info(f"  - –¢–µ—Å—Ç–æ–≤—ã–π —Å–µ–∑–æ–Ω: {test_season}")
    else:
        logger.info(f"  - –¢–µ—Å—Ç–æ–≤—ã–µ —Å–µ–∑–æ–Ω—ã: –ø–æ—Å–ª–µ–¥–Ω–∏–µ {test_seasons_count} (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)")
    logger.info(f"  - –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {output_dir}")
    logger.info("=" * 80)

    try:
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # –®–∞–≥ 1: –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Spark ML
        logger.info("\nüîß –®–∞–≥ 1/3: –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ö–æ–¥–æ–≤ –º–∞—Ç—á–µ–π...")

        with SparkProcessor(db_config) as processor:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
            results = processor.predict_match_outcomes(
                league_filter=league_filter,
                train_seasons_end=train_seasons_end,
                test_season=test_season,
                test_seasons_count=test_seasons_count,
                include_features=features
            )

        logger.info("‚úÖ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

        # –®–∞–≥ 2: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if not skip_visualizations and 'predictions_df' in results:
            logger.info("\nüìä –®–∞–≥ 2/3: –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä
            visualizer = MatchPredictionVisualizer(output_dir=output_dir)

            predictions_df = results['predictions_df']
            metrics = results.get('metrics', {})
            feature_importance = results.get('model_info', {}).get('feature_importance', [])

            # 2.1. Confusion Matrix
            logger.info("  ‚Üí Confusion Matrix...")
            visualizer.plot_confusion_matrix(
                predictions_df=predictions_df,
                save_path=output_path / "confusion_matrix.html",
                show=False
            )

            # 2.2. Feature Importance
            if feature_importance:
                logger.info("  ‚Üí –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
                visualizer.plot_feature_importance(
                    feature_importance=feature_importance,
                    top_n=15,
                    save_path=output_path / "feature_importance.html",
                    show=False
                )

            # 2.3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            logger.info("  ‚Üí –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π...")
            visualizer.plot_probability_distribution(
                predictions_df=predictions_df,
                save_path=output_path / "probability_distribution.html",
                show=False
            )

            # 2.4. –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
            logger.info("  ‚Üí –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫...")
            visualizer.plot_error_analysis(
                predictions_df=predictions_df,
                save_path=output_path / "error_analysis.html",
                show=False
            )

            # 2.5. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π explorer
            logger.info("  ‚Üí –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π explorer...")
            visualizer.plot_prediction_explorer(
                predictions_df=predictions_df,
                save_path=output_path / "prediction_explorer.html",
                show=False
            )

            # 2.6. –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π dashboard
            logger.info("  ‚Üí –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π dashboard...")
            if feature_importance:
                visualizer.create_comprehensive_dashboard(
                    predictions_df=predictions_df,
                    feature_importance=feature_importance,
                    metrics=metrics,
                    save_path=output_path / "comprehensive_dashboard.html",
                    show=False
                )

            # 2.7. –ö—Ä–∏–≤–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
            logger.info("  ‚Üí –ö—Ä–∏–≤–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏...")
            visualizer.plot_calibration_curve(
                predictions_df=predictions_df,
                save_path=output_path / "calibration_curve.html",
                show=False
            )

            # 2.8. –û—Ç—á–µ—Ç –æ –º–æ–¥–µ–ª–∏
            logger.info("  ‚Üí –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –º–æ–¥–µ–ª–∏...")
            report_text = visualizer.generate_model_report(
                predictions_df=predictions_df,
                metrics=metrics,
                feature_importance=feature_importance,
                output_path=output_path / "model_report.txt"
            )

            logger.info(f"‚úÖ –í—Å–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}/")

        elif skip_visualizations:
            logger.info("\nüìä –®–∞–≥ 2/3: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞ (skip_visualizations=True)")

        # –®–∞–≥ 3: –ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤—ã–≤–æ–¥—ã
        logger.info("\nüìà –®–∞–≥ 3/3: –ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑...")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if 'metrics' in results:
            metrics_df = pd.DataFrame([results['metrics']])
            metrics_path = output_path / "model_metrics.csv"
            metrics_df.to_csv(metrics_path, index=False, encoding='utf-8-sig')
            logger.info(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_path}")

            # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
            print("\n" + "=" * 60)
            print("–ò–¢–û–ì–û–í–´–ï –ú–ï–¢–†–ò–ö–ò –ú–û–î–ï–õ–ò:")
            print("=" * 60)
            for metric, value in results['metrics'].items():
                print(f"{metric:15}: {value:.3f}")
            print("=" * 60)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
        if 'predictions_df' in results:
            sample_df = results['predictions_df'].head(20)
            sample_path = output_path / "sample_predictions.csv"
            sample_df.to_csv(sample_path, index=False, encoding='utf-8-sig')
            logger.info(f"‚úÖ –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {sample_path}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –≤ –∫–æ–Ω—Å–æ–ª–∏
            print("\n–ü–†–ò–ú–ï–†–´ –ü–†–û–ì–ù–û–ó–û–í (–ø–µ—Ä–≤—ã–µ 5 –º–∞—Ç—á–µ–π):")
            print("-" * 100)

            display_cols = ['home_team_name', 'away_team_name', 'result',
                            'prediction', 'probabilities']

            if all(col in sample_df.columns for col in display_cols):
                for _, row in sample_df.head().iterrows():
                    actual = {'H': '–î–æ–º–∞', 'D': '–ù–∏—á—å—è', 'A': '–í –≥–æ—Å—Ç—è—Ö'}.get(row['result'], row['result'])
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º prediction –≤ int, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –≤–æ–∑–º–æ–∂–Ω—ã–µ NaN/None
                    pred_val = row['prediction']
                    if pd.isna(pred_val) or pred_val is None:
                        predicted = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                    else:
                        pred_idx = int(float(pred_val))  # –°–Ω–∞—á–∞–ª–∞ float, –ø–æ—Ç–æ–º int –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                        predicted = ['–î–æ–º–∞', '–ù–∏—á—å—è', '–í –≥–æ—Å—Ç—è—Ö'][pred_idx]

                    print(f"{row['home_team_name']:20} vs {row['away_team_name']:20}")
                    print(f"  –§–∞–∫—Ç: {actual:10} | –ü—Ä–æ–≥–Ω–æ–∑: {predicted:10}")
                    print(f"  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: {row['probabilities']}")
                    print("-" * 100)

        # –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        logger.info("\nüìã –ê–ù–ê–õ–ò–ó –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–ò –ú–û–î–ï–õ–ò:")

        if 'predictions_df' in results:
            predictions_df = results['predictions_df']

            # –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ —Ç–∏–ø–∞–º –º–∞—Ç—á–µ–π
            predictions_df['is_correct'] = (
                    predictions_df['result_numeric'] == predictions_df['prediction']
            )

            total_matches = len(predictions_df)
            correct_matches = predictions_df['is_correct'].sum()
            accuracy = correct_matches / total_matches

            logger.info(f"  –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.1%} ({correct_matches}/{total_matches})")

            # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –∏—Å—Ö–æ–¥–æ–≤
            for result_type, result_name in [('H', '–î–æ–º–∞—à–Ω–∏–µ –ø–æ–±–µ–¥—ã'),
                                             ('D', '–ù–∏—á—å–∏'),
                                             ('A', '–í—ã–µ–∑–¥–Ω—ã–µ –ø–æ–±–µ–¥—ã')]:
                mask = predictions_df['result'] == result_type
                if mask.any():
                    subset = predictions_df[mask]
                    subset_accuracy = subset['is_correct'].mean()
                    logger.info(f"  {result_name}: {subset_accuracy:.1%} "
                                f"({subset['is_correct'].sum()}/{len(subset)})")

            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
            baseline_home = (predictions_df['result'] == 'H').mean()
            logger.info(f"  –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (–≤—Å–µ–≥–¥–∞ –¥–æ–º–∞): {baseline_home:.1%}")
            logger.info(f"  –£–ª—É—á—à–µ–Ω–∏–µ: {accuracy - baseline_home:+.1%}")

        # –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("\n" + "=" * 80)
        print("–í–´–í–û–î–´ –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        print("=" * 80)

        conclusions = [
            "1. –ú–æ–¥–µ–ª—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –≤—ã—à–µ –±–∞–∑–æ–≤—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤",
            "2. –ù–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: —Ñ–æ—Ä–º–∞ –∫–æ–º–∞–Ω–¥ –∏ –ø–æ–∑–∏—Ü–∏—è –≤ —Ç–∞–±–ª–∏—Ü–µ",
            "3. –°–ª–æ–∂–Ω–µ–µ –≤—Å–µ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∏—á—å–∏ (—Å–∞–º—ã–π —Ä–µ–¥–∫–∏–π –∏—Å—Ö–æ–¥)",
            "4. –î–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:",
            "   ‚Ä¢ –î–æ–±–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ —Å–æ—Å—Ç–∞–≤–∞—Ö –∏ —Ç—Ä–∞–≤–º–∞—Ö",
            "   ‚Ä¢ –£—á–µ—Å—Ç—å –º–æ—Ç–∏–≤–∞—Ü–∏—é –∫–æ–º–∞–Ω–¥ (—Ç—É—Ä–Ω–∏—Ä–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ)",
            "   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª—å –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π",
            "   ‚Ä¢ –î–æ–±–∞–≤–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"
        ]

        for conclusion in conclusions:
            print(conclusion)

        print("=" * 80)
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")
        print("=" * 80)

        return results

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∞: {e}", exc_info=True)
        raise


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞"""

    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser = argparse.ArgumentParser(
        description='–ó–∞–¥–∞—á–∞ 5: –ü—Ä–æ–≥–Ω–æ–∑ –∏—Å—Ö–æ–¥–æ–≤ –º–∞—Ç—á–µ–π —á–µ—Ä–µ–∑ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'
    )
    parser.add_argument(
        '--config',
        type=str,
        default=None,
        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (default: ../database/config.yaml)'
    )
    parser.add_argument(
        '--league',
        type=str,
        default='epl',
        help='–§–∏–ª—å—Ç—Ä –ø–æ –ª–∏–≥–µ (default: epl)'
    )
    parser.add_argument(
        '--train-end',
        type=str,
        default=None,
        help='–ü–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–∑–æ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (default: None - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ)'
    )
    parser.add_argument(
        '--test-season',
        type=str,
        default=None,
        help='–°–µ–∑–æ–Ω –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (default: None - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ test-seasons-count —Å–µ–∑–æ–Ω–æ–≤)'
    )
    parser.add_argument(
        '--test-seasons-count',
        type=int,
        default=1,
        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–µ–∑–æ–Ω–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –µ—Å–ª–∏ test-season –Ω–µ —É–∫–∞–∑–∞–Ω, default: 1)'
    )
    parser.add_argument(
        '--features',
        type=str,
        nargs='+',
        default=None,
        help='–°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (—á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='outputs/task5',
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (default: outputs/task5)'
    )
    parser.add_argument(
        '--skip-viz',
        action='store_true',
        help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π'
    )
    parser.add_argument(
        '--log-level',
        type=str,
        default='INFO',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        help='–£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (default: INFO)'
    )

    args = parser.parse_args()

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    setup_logging(args.log_level)

    logger = logging.getLogger(__name__)

    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config = load_config(args.config)
        db_config = config.get('database', {})

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ë–î
        required_params = ['host', 'port', 'database', 'user', 'password']
        missing_params = [p for p in required_params if p not in db_config]

        if missing_params:
            raise ValueError(
                f"–í –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ë–î: {missing_params}"
            )

        # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞
        results = run_task5_analysis(
            db_config=db_config,
            league_filter=args.league,
            train_seasons_end=args.train_end,
            test_season=args.test_season,
            test_seasons_count=args.test_seasons_count,
            features=args.features,
            output_dir=args.output,
            skip_visualizations=args.skip_viz
        )

        logger.info("‚úÖ –ü—Ä–æ–≥—Ä–∞–º–º–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        return 0

    except KeyboardInterrupt:
        logger.warning("‚ùå –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 130
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        return 1


if __name__ == '__main__':
    sys.exit(main())